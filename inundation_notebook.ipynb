{
 "metadata": {
  "name": "",
  "signature": "sha256:ef8fc3966a5c57e54768c872131711b2ffb318311661f736110f85c3e03bb3fd"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time\n",
      "\n",
      "\n",
      "start_time = time.time()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pytz\n",
      "from datetime import datetime, timedelta\n",
      "\n",
      "\n",
      "# Choose the date range (e.g: stop = datetime(2014, 7, 7, 12)).\n",
      "stop = datetime(2015, 1, 30, 12)\n",
      "run_name = '{:%Y-%m-%d}'.format(stop)\n",
      "\n",
      "stop = stop.replace(tzinfo=pytz.utc)\n",
      "start = stop - timedelta(days=7)\n",
      "\n",
      "# NERACOOS Mass Bay Region.\n",
      "bbox = [-72.0, 41.0, -69.0, 43.0]\n",
      "\n",
      "# CF-names to look for (Sea Surface Height).\n",
      "name_list = ['sea_surface_height',\n",
      "             'sea_surface_elevation',\n",
      "             'sea_surface_height_above_geoid',\n",
      "             'sea_surface_height_above_sea_level',\n",
      "             'water_surface_height_above_reference_datum',\n",
      "             'sea_surface_height_above_reference_ellipsoid']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import iris\n",
      "import pyoos\n",
      "import owslib\n",
      "\n",
      "import logging as log\n",
      "reload(log)\n",
      "\n",
      "fmt = '{:*^64}'.format\n",
      "log.captureWarnings(True)\n",
      "LOG_FILENAME = 'log.txt'\n",
      "log.basicConfig(filename=LOG_FILENAME,\n",
      "                filemode='w',\n",
      "                format='%(asctime)s %(levelname)s: %(message)s',\n",
      "                datefmt='%I:%M:%S',\n",
      "                level=log.INFO,\n",
      "                stream=None)\n",
      "\n",
      "log.info(fmt(' Run information '))\n",
      "log.info('Run date: {:%Y-%m-%d %H:%M:%S}'.format(datetime.utcnow()))\n",
      "log.info('Download start: {:%Y-%m-%d %H:%M:%S}'.format(start))\n",
      "log.info('Download stop: {:%Y-%m-%d %H:%M:%S}'.format(stop))\n",
      "log.info('Bounding box: {0:3.2f}, {1:3.2f},'\n",
      "         '{2:3.2f}, {3:3.2f}'.format(*bbox))\n",
      "log.info(fmt(' Software version '))\n",
      "log.info('Iris version: {}'.format(iris.__version__))\n",
      "log.info('owslib version: {}'.format(owslib.__version__))\n",
      "log.info('pyoos version: {}'.format(pyoos.__version__))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def fes_date_filter(start, stop, constraint='overlaps'):\n",
      "    \"\"\"Take datetime-like objects and returns a fes filter for date range.\n",
      "    NOTE: Truncates the minutes!\"\"\"\n",
      "    start = start.strftime('%Y-%m-%d %H:00')\n",
      "    stop = stop.strftime('%Y-%m-%d %H:00')\n",
      "    if constraint == 'overlaps':\n",
      "        propertyname = 'apiso:TempExtent_begin'\n",
      "        begin = fes.PropertyIsLessThanOrEqualTo(propertyname=propertyname,\n",
      "                                                literal=stop)\n",
      "        propertyname = 'apiso:TempExtent_end'\n",
      "        end = fes.PropertyIsGreaterThanOrEqualTo(propertyname=propertyname,\n",
      "                                                 literal=start)\n",
      "    elif constraint == 'within':\n",
      "        propertyname = 'apiso:TempExtent_begin'\n",
      "        begin = fes.PropertyIsGreaterThanOrEqualTo(propertyname=propertyname,\n",
      "                                                   literal=start)\n",
      "        propertyname = 'apiso:TempExtent_end'\n",
      "        end = fes.PropertyIsLessThanOrEqualTo(propertyname=propertyname,\n",
      "                                              literal=stop)\n",
      "    else:\n",
      "        raise NameError('Unrecognized constraint {}'.format(constraint))\n",
      "    return begin, end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from owslib import fes\n",
      "\n",
      "kw = dict(wildCard='*',\n",
      "          escapeChar='\\\\',\n",
      "          singleChar='?',\n",
      "          propertyname='apiso:AnyText')\n",
      "\n",
      "or_filt = fes.Or([fes.PropertyIsLike(literal=('*%s*' % val), **kw)\n",
      "                  for val in name_list])\n",
      "\n",
      "# Exculde ROMS Averages and History files.\n",
      "not_filt = fes.Not([fes.PropertyIsLike(literal='*Averages*', **kw)])\n",
      "\n",
      "begin, end = fes_date_filter(start, stop)\n",
      "filter_list = [fes.And([fes.BBox(bbox), begin, end, or_filt, not_filt])]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from owslib.csw import CatalogueServiceWeb\n",
      "\n",
      "endpoint = 'http://www.ngdc.noaa.gov/geoportal/csw'\n",
      "csw = CatalogueServiceWeb(endpoint, timeout=60)\n",
      "csw.getrecords2(constraints=filter_list, maxrecords=1000, esn='full')\n",
      "\n",
      "log.info(fmt(' Catalog information '))\n",
      "log.info(\"URL: {}\".format(endpoint))\n",
      "log.info(\"CSW version: {}\".format(csw.version))\n",
      "log.info(\"Number of datasets available: {}\".format(len(csw.records.keys())))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def service_urls(records, service='odp:url'):\n",
      "    \"\"\"Extract service_urls of a specific type (DAP, SOS) from records.\"\"\"\n",
      "    service_string = 'urn:x-esri:specification:ServiceType:' + service\n",
      "    urls = []\n",
      "    for key, rec in records.items():\n",
      "        # Create a generator object, and iterate through it until the match is\n",
      "        # found if not found, gets the default value (here \"none\").\n",
      "        url = next((d['url'] for d in rec.references if\n",
      "                    d['scheme'] == service_string), None)\n",
      "        if url is not None:\n",
      "            urls.append(url)\n",
      "    urls = sorted(set(urls))\n",
      "    return urls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dap_urls = service_urls(csw.records, service='odp:url')\n",
      "sos_urls = service_urls(csw.records, service='sos:url')\n",
      "\n",
      "log.info(fmt(' CSW '))\n",
      "for rec, item in csw.records.items():\n",
      "    log.info('{}'.format(item.title))\n",
      "\n",
      "log.info(fmt(' DAP '))\n",
      "for url in dap_urls:\n",
      "    log.info('{}.html'.format(url))\n",
      "\n",
      "log.info(fmt(' SOS '))\n",
      "for url in sos_urls:\n",
      "    log.info('{}'.format(url))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyoos.collectors.coops.coops_sos import CoopsSos\n",
      "\n",
      "collector = CoopsSos()\n",
      "sos_name = 'water_surface_height_above_reference_datum'\n",
      "\n",
      "datum = 'NAVD'\n",
      "collector.set_datum(datum)\n",
      "collector.end_time = stop\n",
      "collector.start_time = start\n",
      "collector.variables = [sos_name]\n",
      "\n",
      "ofrs = collector.server.offerings\n",
      "title = collector.server.identification.title\n",
      "log.info(fmt(' Collector offerings '))\n",
      "log.info('{}: {} offerings'.format(title, len(ofrs)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import requests\n",
      "from urlparse import urlparse\n",
      "\n",
      "\n",
      "# Web-parsing.\n",
      "def parse_url(url):\n",
      "    \"\"\"This will preserve any given scheme but will add http if none is\n",
      "    provided.\"\"\"\n",
      "    if not urlparse(url).scheme:\n",
      "        url = \"http://{}\".format(url)\n",
      "    return url\n",
      "\n",
      "\n",
      "def sos_request(url='opendap.co-ops.nos.noaa.gov/ioos-dif-sos/SOS', **kw):\n",
      "    url = parse_url(url)\n",
      "    offering = 'urn:ioos:network:NOAA.NOS.CO-OPS:CurrentsActive'\n",
      "    params = dict(service='SOS',\n",
      "                  request='GetObservation',\n",
      "                  version='1.0.0',\n",
      "                  offering=offering,\n",
      "                  responseFormat='text/csv')\n",
      "    params.update(kw)\n",
      "    r = requests.get(url, params=params)\n",
      "    r.raise_for_status()\n",
      "    content = r.headers['Content-Type']\n",
      "    if 'excel' in content or 'csv' in content:\n",
      "        return r.url\n",
      "    else:\n",
      "        raise TypeError('Bad url {}'.format(r.url))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pandas import read_csv\n",
      "\n",
      "params = dict(observedProperty=sos_name,\n",
      "              eventTime=start.strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
      "              featureOfInterest='BBOX:{0},{1},{2},{3}'.format(*bbox),\n",
      "              offering='urn:ioos:network:NOAA.NOS.CO-OPS:WaterLevelActive')\n",
      "\n",
      "uri = 'http://opendap.co-ops.nos.noaa.gov/ioos-dif-sos/SOS'\n",
      "url = sos_request(uri, **params)\n",
      "observations = read_csv(url)\n",
      "\n",
      "log.info('SOS URL request: {}'.format(url))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Clean the dataframe (visualization purpose only)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from lxml import etree\n",
      "from urllib import urlopen\n",
      "from IPython.display import HTML\n",
      "\n",
      "\n",
      "def get_coops_longname(station):\n",
      "    \"\"\"Get longName for specific station from COOPS SOS using DescribeSensor\n",
      "    request.\"\"\"\n",
      "    url = ('opendap.co-ops.nos.noaa.gov/ioos-dif-sos/SOS?service=SOS&'\n",
      "           'request=DescribeSensor&version=1.0.0&'\n",
      "           'outputFormat=text/xml;subtype=\"sensorML/1.0.1\"&'\n",
      "           'procedure=urn:ioos:station:NOAA.NOS.CO-OPS:%s') % station\n",
      "    url = parse_url(url)\n",
      "    tree = etree.parse(urlopen(url))\n",
      "    root = tree.getroot()\n",
      "    path = \"//sml:identifier[@name='longName']/sml:Term/sml:value/text()\"\n",
      "    namespaces = dict(sml=\"http://www.opengis.net/sensorML/1.0.1\")\n",
      "    longName = root.xpath(path, namespaces=namespaces)\n",
      "    if len(longName) == 0:\n",
      "        longName = station\n",
      "    return longName[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "columns = {'datum_id': 'datum',\n",
      "           'sensor_id': 'sensor',\n",
      "           'station_id': 'station',\n",
      "           'latitude (degree)': 'lat',\n",
      "           'longitude (degree)': 'lon',\n",
      "           'vertical_position (m)': 'height',\n",
      "           'water_surface_height_above_reference_datum (m)': 'ssh above datum'}\n",
      "\n",
      "observations.rename(columns=columns, inplace=True)\n",
      "\n",
      "observations['datum'] = [s.split(':')[-1] for s in observations['datum']]\n",
      "observations['sensor'] = [s.split(':')[-1] for s in observations['sensor']]\n",
      "observations['station'] = [s.split(':')[-1] for s in observations['station']]\n",
      "observations['name'] = [get_coops_longname(s) for s in observations['station']]\n",
      "\n",
      "observations.set_index('name', inplace=True)\n",
      "\n",
      "observations.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>station</th>\n",
        "      <th>sensor</th>\n",
        "      <th>lat</th>\n",
        "      <th>lon</th>\n",
        "      <th>date_time</th>\n",
        "      <th>ssh above datum</th>\n",
        "      <th>datum</th>\n",
        "      <th>height</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>name</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>Boston, MA</th>\n",
        "      <td> 8443970</td>\n",
        "      <td> B1</td>\n",
        "      <td> 42.3548</td>\n",
        "      <td>-71.0534</td>\n",
        "      <td> 2015-01-23T12:00:00Z</td>\n",
        "      <td>-0.341</td>\n",
        "      <td> MLLW</td>\n",
        "      <td> 1.074</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Fall River, MA</th>\n",
        "      <td> 8447386</td>\n",
        "      <td> B1</td>\n",
        "      <td> 41.7043</td>\n",
        "      <td>-71.1641</td>\n",
        "      <td> 2015-01-23T12:00:00Z</td>\n",
        "      <td> 0.555</td>\n",
        "      <td> MLLW</td>\n",
        "      <td> 6.356</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Chatham, MA</th>\n",
        "      <td> 8447435</td>\n",
        "      <td> A1</td>\n",
        "      <td> 41.6885</td>\n",
        "      <td>-69.9511</td>\n",
        "      <td> 2015-01-23T12:00:00Z</td>\n",
        "      <td> 0.403</td>\n",
        "      <td> MLLW</td>\n",
        "      <td> 1.003</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Woods Hole, MA</th>\n",
        "      <td> 8447930</td>\n",
        "      <td> A1</td>\n",
        "      <td> 41.5233</td>\n",
        "      <td>-70.6717</td>\n",
        "      <td> 2015-01-23T12:00:00Z</td>\n",
        "      <td> 0.100</td>\n",
        "      <td> MLLW</td>\n",
        "      <td> 0.797</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Nantucket Island, MA</th>\n",
        "      <td> 8449130</td>\n",
        "      <td> B1</td>\n",
        "      <td> 41.2850</td>\n",
        "      <td>-70.0967</td>\n",
        "      <td> 2015-01-23T12:00:00Z</td>\n",
        "      <td> 0.004</td>\n",
        "      <td> MLLW</td>\n",
        "      <td> 0.915</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "                      station sensor      lat      lon             date_time  \\\n",
        "name                                                                           \n",
        "Boston, MA            8443970     B1  42.3548 -71.0534  2015-01-23T12:00:00Z   \n",
        "Fall River, MA        8447386     B1  41.7043 -71.1641  2015-01-23T12:00:00Z   \n",
        "Chatham, MA           8447435     A1  41.6885 -69.9511  2015-01-23T12:00:00Z   \n",
        "Woods Hole, MA        8447930     A1  41.5233 -70.6717  2015-01-23T12:00:00Z   \n",
        "Nantucket Island, MA  8449130     B1  41.2850 -70.0967  2015-01-23T12:00:00Z   \n",
        "\n",
        "                      ssh above datum datum  height  \n",
        "name                                                 \n",
        "Boston, MA                     -0.341  MLLW   1.074  \n",
        "Fall River, MA                  0.555  MLLW   6.356  \n",
        "Chatham, MA                     0.403  MLLW   1.003  \n",
        "Woods Hole, MA                  0.100  MLLW   0.797  \n",
        "Nantucket Island, MA            0.004  MLLW   0.915  "
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Generate a uniform 6-min time base for model/data comparison"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from io import BytesIO\n",
      "from iris.pandas import as_cube\n",
      "\n",
      "\n",
      "def coops2df(collector, coops_id):\n",
      "    \"\"\"Request CSV response from SOS and convert to Pandas DataFrames.\"\"\"\n",
      "    collector.features = [coops_id]\n",
      "    long_name = get_coops_longname(coops_id)\n",
      "    response = collector.raw(responseFormat=\"text/csv\")\n",
      "    kw = dict(parse_dates=True, index_col='date_time')\n",
      "    data_df = read_csv(BytesIO(response.encode('utf-8')), **kw)\n",
      "    data_df.name = long_name\n",
      "    return data_df\n",
      "\n",
      "\n",
      "def save_timeseries(df, outfile, standard_name, **kw):\n",
      "    \"\"\"http://cfconventions.org/Data/cf-convetions/cf-conventions-1.6/build\n",
      "    /cf-conventions.html#idp5577536\"\"\"\n",
      "    cube = as_cube(df, calendars={1: iris.unit.CALENDAR_GREGORIAN})\n",
      "    cube.coord(\"index\").rename(\"time\")\n",
      "    cube.coord(\"columns\").rename(\"station name\")\n",
      "    cube.rename(standard_name)\n",
      "\n",
      "    longitude = kw.get(\"longitude\")\n",
      "    latitude = kw.get(\"latitude\")\n",
      "    if longitude is not None:\n",
      "        longitude = iris.coords.AuxCoord(longitude,\n",
      "                                         var_name=\"lon\",\n",
      "                                         standard_name=\"longitude\",\n",
      "                                         long_name=\"station longitude\",\n",
      "                                         units=iris.unit.Unit(\"degrees\"))\n",
      "    cube.add_aux_coord(longitude, data_dims=1)\n",
      "\n",
      "    if latitude is not None:\n",
      "        latitude = iris.coords.AuxCoord(latitude,\n",
      "                                        var_name=\"lat\",\n",
      "                                        standard_name=\"latitude\",\n",
      "                                        long_name=\"station latitude\",\n",
      "                                        units=iris.unit.Unit(\"degrees\"))\n",
      "        cube.add_aux_coord(latitude, data_dims=1)\n",
      "\n",
      "    # Work around iris to get String instead of np.array object.\n",
      "    string_list = cube.coord(\"station name\").points.tolist()\n",
      "    cube.coord(\"station name\").points = string_list\n",
      "    cube.coord(\"station name\").var_name = 'station'\n",
      "\n",
      "    station_attr = kw.get(\"station_attr\")\n",
      "    if station_attr is not None:\n",
      "        cube.coord(\"station name\").attributes.update(station_attr)\n",
      "\n",
      "    cube_attr = kw.get(\"cube_attr\")\n",
      "    if cube_attr is not None:\n",
      "        cube.attributes.update(cube_attr)\n",
      "\n",
      "    iris.save(cube, outfile)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import iris\n",
      "from pandas import DataFrame\n",
      "from owslib.ows import ExceptionReport\n",
      "\n",
      "iris.FUTURE.netcdf_promote = True\n",
      "\n",
      "log.info(fmt(' Observations '))\n",
      "fname = '{:%Y-%m-%d}-OBS_DATA.nc'.format(stop)\n",
      "\n",
      "log.info(fmt(' Downloading to file {} '.format(fname)))\n",
      "data = dict()\n",
      "bad_datum = []\n",
      "for station in observations.station:\n",
      "    try:\n",
      "        df = coops2df(collector, station)\n",
      "        col = 'water_surface_height_above_reference_datum (m)'\n",
      "        data.update({station: df[col]})\n",
      "    except ExceptionReport as e:\n",
      "        bad_datum.append(station)\n",
      "        name = get_coops_longname(station)\n",
      "        log.warning(\"[{}] {}:\\n{}\".format(station, name, e))\n",
      "obs_data = DataFrame.from_dict(data)\n",
      "\n",
      "# Split good and bad vertical datum stations.\n",
      "pattern = '|'.join(bad_datum)\n",
      "if pattern:\n",
      "    non_navd = observations.station.str.contains(pattern)\n",
      "    bad_datum = observations[non_navd]\n",
      "    observations = observations[~non_navd]\n",
      "\n",
      "comment = \"Several stations from http://opendap.co-ops.nos.noaa.gov\"\n",
      "kw = dict(longitude=observations.lon,\n",
      "          latitude=observations.lat,\n",
      "          station_attr=dict(cf_role=\"timeseries_id\"),\n",
      "          cube_attr=dict(featureType='timeSeries',\n",
      "                         Conventions='CF-1.6',\n",
      "                         standard_name_vocabulary='CF-1.6',\n",
      "                         cdm_data_type=\"Station\",\n",
      "                         comment=comment,\n",
      "                         datum=datum,\n",
      "                         url=url))\n",
      "\n",
      "save_timeseries(obs_data, outfile=fname,\n",
      "                standard_name=sos_name, **kw)\n",
      "\n",
      "obs_data.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>8443970</th>\n",
        "      <th>8447435</th>\n",
        "      <th>8447930</th>\n",
        "      <th>8452660</th>\n",
        "      <th>8454000</th>\n",
        "      <th>8510560</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>date_time</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>2015-01-23 12:00:00</th>\n",
        "      <td>-2.020</td>\n",
        "      <td>-0.628</td>\n",
        "      <td>-0.315</td>\n",
        "      <td>-0.108</td>\n",
        "      <td>-0.195</td>\n",
        "      <td>-0.271</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2015-01-23 12:06:00</th>\n",
        "      <td>-2.017</td>\n",
        "      <td>-0.651</td>\n",
        "      <td>-0.290</td>\n",
        "      <td>-0.071</td>\n",
        "      <td>-0.151</td>\n",
        "      <td>-0.254</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2015-01-23 12:12:00</th>\n",
        "      <td>-2.004</td>\n",
        "      <td>-0.673</td>\n",
        "      <td>-0.264</td>\n",
        "      <td>-0.030</td>\n",
        "      <td>-0.099</td>\n",
        "      <td>-0.224</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2015-01-23 12:18:00</th>\n",
        "      <td>-1.992</td>\n",
        "      <td>-0.696</td>\n",
        "      <td>-0.218</td>\n",
        "      <td> 0.011</td>\n",
        "      <td>-0.045</td>\n",
        "      <td>-0.205</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2015-01-23 12:24:00</th>\n",
        "      <td>-1.966</td>\n",
        "      <td>-0.719</td>\n",
        "      <td>-0.202</td>\n",
        "      <td> 0.055</td>\n",
        "      <td>-0.006</td>\n",
        "      <td>-0.190</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "                     8443970  8447435  8447930  8452660  8454000  8510560\n",
        "date_time                                                                \n",
        "2015-01-23 12:00:00   -2.020   -0.628   -0.315   -0.108   -0.195   -0.271\n",
        "2015-01-23 12:06:00   -2.017   -0.651   -0.290   -0.071   -0.151   -0.254\n",
        "2015-01-23 12:12:00   -2.004   -0.673   -0.264   -0.030   -0.099   -0.224\n",
        "2015-01-23 12:18:00   -1.992   -0.696   -0.218    0.011   -0.045   -0.205\n",
        "2015-01-23 12:24:00   -1.966   -0.719   -0.202    0.055   -0.006   -0.190"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Loop discovered models and save the nearest time-series"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import signal\n",
      "from contextlib import contextmanager\n",
      "\n",
      "import numpy as np\n",
      "from oceans import wrap_lon180\n",
      "\n",
      "from iris import Constraint\n",
      "from iris.cube import CubeList\n",
      "from iris.exceptions import CoordinateMultiDimError\n",
      "\n",
      "water_level = ['sea_surface_height',\n",
      "               'sea_surface_elevation',\n",
      "               'sea_surface_height_above_geoid',\n",
      "               'sea_surface_height_above_sea_level',\n",
      "               'water_surface_height_above_reference_datum',\n",
      "               'sea_surface_height_above_reference_ellipsoid']\n",
      "\n",
      "\n",
      "class TimeoutException(Exception):\n",
      "    \"\"\"\n",
      "    Example\n",
      "    -------\n",
      "    >>> def long_function_call():\n",
      "    >>>     import time\n",
      "    >>>     sec = 0\n",
      "    >>>>    while True:\n",
      "    >>>         sec += 1\n",
      "    >>>         print(sec)\n",
      "    >>>         time.sleep(1)\n",
      "    >>>\n",
      "    >>> try:\n",
      "    >>>     with time_limit(10):\n",
      "    >>>     long_function_call()\n",
      "    >>> except TimeoutException as msg:\n",
      "    >>>     print(\"Timed out!\")\n",
      "    \"\"\"\n",
      "    pass\n",
      "\n",
      "\n",
      "@contextmanager\n",
      "def time_limit(seconds=10):\n",
      "    def signal_handler(signum, frame):\n",
      "        raise TimeoutException(\"Timed out!\")\n",
      "    signal.signal(signal.SIGALRM, signal_handler)\n",
      "    signal.alarm(seconds)\n",
      "    try:\n",
      "        yield\n",
      "    finally:\n",
      "        signal.alarm(0)\n",
      "\n",
      "\n",
      "# Iris.\n",
      "def z_coord(cube):\n",
      "    \"\"\"Heuristic way to return **one** the vertical coordinate.\"\"\"\n",
      "    try:\n",
      "        z = cube.coord(axis='Z')\n",
      "    except CoordinateNotFoundError:\n",
      "        z = None\n",
      "        for coord in cube.coords(axis='Z'):\n",
      "            if coord.name() not in water_level:\n",
      "                z = coord\n",
      "    return z\n",
      "\n",
      "\n",
      "def get_surface(cube):\n",
      "    \"\"\"Work around `iris.cube.Cube.slices` error:\n",
      "    The requested coordinates are not orthogonal.\"\"\"\n",
      "    z = z_coord(cube)\n",
      "    if z:\n",
      "        positive = z.attributes.get('positive', None)\n",
      "        if positive == 'up':\n",
      "            idx = np.unique(z.points.argmax(axis=0))[0]\n",
      "        else:\n",
      "            idx = np.unique(z.points.argmin(axis=0))[0]\n",
      "        return cube[:, idx, ...]\n",
      "    else:\n",
      "        return cube\n",
      "\n",
      "\n",
      "def time_coord(cube):\n",
      "    \"\"\"Return the variable attached to time axis and rename it to time.\"\"\"\n",
      "    try:\n",
      "        cube.coord(axis='T').rename('time')\n",
      "    except CoordinateNotFoundError:\n",
      "        pass\n",
      "    timevar = cube.coord('time')\n",
      "    return timevar\n",
      "\n",
      "\n",
      "def time_near(cube, datetime):\n",
      "    \"\"\"Return the nearest index to a `datetime`.\"\"\"\n",
      "    timevar = time_coord(cube)\n",
      "    try:\n",
      "        time = timevar.units.date2num(datetime)\n",
      "        idx = timevar.nearest_neighbour_index(time)\n",
      "    except IndexError:\n",
      "        idx = -1\n",
      "    return idx\n",
      "\n",
      "\n",
      "def time_slice(cube, start, stop=None):\n",
      "    \"\"\"Slice time by indexes using a nearest criteria.\n",
      "    NOTE: Assumes time is the first dimension!\"\"\"\n",
      "    istart = time_near(cube, start)\n",
      "    if stop:\n",
      "        istop = time_near(cube, stop)\n",
      "        if istart == istop:\n",
      "            raise ValueError('istart must be different from istop! '\n",
      "                             'Got istart {!r} and '\n",
      "                             ' istop {!r}'.format(istart, istop))\n",
      "        return cube[istart:istop, ...]\n",
      "    else:\n",
      "        return cube[istart, ...]\n",
      "\n",
      "\n",
      "def time_constraint(cube, start, stop):\n",
      "    \"\"\"Slice time by constraint.\"\"\"\n",
      "    begin = lambda cell: cell >= start\n",
      "    end = lambda cell: cell <= stop\n",
      "    constraint = Constraint(begin & end)\n",
      "    return cube.extract(constraint)\n",
      "\n",
      "\n",
      "def minmax(v):\n",
      "    return np.min(v), np.max(v)\n",
      "\n",
      "\n",
      "def bbox_extract_2Dcoords(cube, bbox):\n",
      "    \"\"\"Extract a sub-set of a cube inside a lon, lat bounding box\n",
      "    bbox=[lon_min lon_max lat_min lat_max].\n",
      "    NOTE: This is a work around too subset an iris cube that has\n",
      "    2D lon, lat coords.\"\"\"\n",
      "    lons = cube.coord('longitude').points\n",
      "    lats = cube.coord('latitude').points\n",
      "    lons = wrap_lon180(lons)\n",
      "\n",
      "    inregion = np.logical_and(np.logical_and(lons > bbox[0],\n",
      "                                             lons < bbox[2]),\n",
      "                              np.logical_and(lats > bbox[1],\n",
      "                                             lats < bbox[3]))\n",
      "    region_inds = np.where(inregion)\n",
      "    imin, imax = minmax(region_inds[0])\n",
      "    jmin, jmax = minmax(region_inds[1])\n",
      "    return cube[..., imin:imax+1, jmin:jmax+1]\n",
      "\n",
      "\n",
      "def bbox_extract_1Dcoords(cube, bbox):\n",
      "    lat = Constraint(latitude=lambda cell: bbox[1] <= cell < bbox[3])\n",
      "    lon = Constraint(longitude=lambda cell: bbox[0] <= cell <= bbox[2])\n",
      "    cube = cube.extract(lon & lat)\n",
      "    return cube\n",
      "\n",
      "\n",
      "def subset(cube, bbox):\n",
      "    \"\"\"Sub sets cube with 1D or 2D lon, lat coords.\n",
      "    Using `intersection` instead of `extract` we deal with 0--360\n",
      "    longitudes automagically.\"\"\"\n",
      "    if (cube.coord(axis='X').ndim == 1 and cube.coord(axis='Y').ndim == 1):\n",
      "        # Workaround `cube.intersection` hanging up on FVCOM models.\n",
      "        title = cube.attributes.get('title', None)\n",
      "        featureType = cube.attributes.get('featureType', None)\n",
      "        if (('FVCOM' in title) or ('ESTOFS' in title) or\n",
      "           featureType == 'timeSeries'):\n",
      "            cube = bbox_extract_1Dcoords(cube, bbox)\n",
      "        else:\n",
      "            cube = cube.intersection(longitude=(bbox[0], bbox[2]),\n",
      "                                     latitude=(bbox[1], bbox[3]))\n",
      "    elif (cube.coord(axis='X').ndim == 2 and\n",
      "          cube.coord(axis='Y').ndim == 2):\n",
      "        cube = bbox_extract_2Dcoords(cube, bbox)\n",
      "    else:\n",
      "        msg = \"Cannot deal with X:{!r} and Y:{!r} dimensions.\"\n",
      "        raise CoordinateMultiDimError(msg.format(cube.coord(axis='X').ndim),\n",
      "                                      cube.coord(axis='y').ndim)\n",
      "    return cube\n",
      "\n",
      "\n",
      "def get_cube(url, name_list, bbox=None, time=None, units=None, callback=None,\n",
      "             constraint=None):\n",
      "    \"\"\"Only `url` and `name_list` are mandatory.  The kw args are:\n",
      "    `bbox`, `callback`, `time`, `units`, `constraint`.\"\"\"\n",
      "\n",
      "    cubes = iris.load_raw(url, callback=callback)\n",
      "\n",
      "    in_list = lambda cube: cube.standard_name in name_list\n",
      "    cubes = CubeList([cube for cube in cubes if in_list(cube)])\n",
      "    if not cubes:\n",
      "        raise ValueError('Cube does not contain {!r}'.format(name_list))\n",
      "    else:\n",
      "        cube = cubes.merge_cube()\n",
      "\n",
      "    if constraint:\n",
      "        cube = cube.extract(constraint)\n",
      "        if not cube:\n",
      "            raise ValueError('No cube using {!r}'.format(constraint))\n",
      "    if bbox:\n",
      "        cube = subset(cube, bbox)\n",
      "        if not cube:\n",
      "            raise ValueError('No cube using {!r}'.format(bbox))\n",
      "    if time:\n",
      "        if isinstance(time, datetime):\n",
      "            start, stop = time, None\n",
      "        elif isinstance(time, tuple):\n",
      "            start, stop = time[0], time[1]\n",
      "        else:\n",
      "            raise ValueError('Time must be start or (start, stop).'\n",
      "                             '  Got {!r}'.format(time))\n",
      "        cube = time_slice(cube, start, stop)\n",
      "    if units:\n",
      "        if cube.units != units:\n",
      "            cube.convert_units(units)\n",
      "    return cube\n",
      "\n",
      "\n",
      "def get_model_name(cube, url):\n",
      "    url = parse_url(url)\n",
      "    try:\n",
      "        model_full_name = cube.attributes['title']\n",
      "    except AttributeError:\n",
      "        model_full_name = url\n",
      "    mod_name = model_full_name.split()[0]\n",
      "    return mod_name, model_full_name"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import warnings\n",
      "from iris.exceptions import (CoordinateNotFoundError, ConstraintMismatchError,\n",
      "                             MergeError)\n",
      "\n",
      "\n",
      "log.info(fmt(' Models '))\n",
      "cubes = dict()\n",
      "\n",
      "with warnings.catch_warnings():\n",
      "    # Suppress iris warnings :\n",
      "    warnings.simplefilter(\"ignore\")\n",
      "    for k, url in enumerate(dap_urls):\n",
      "        log.info('\\n[Reading url {}/{}]: {}'.format(k+1, len(dap_urls), url))\n",
      "        try:\n",
      "            with time_limit(60*5):\n",
      "                cube = get_cube(url, name_list=name_list,\n",
      "                                bbox=bbox, time=(start, stop),\n",
      "                                units=iris.unit.Unit('meters'))\n",
      "            # TODO: Need a better way to identify model data and observed data.\n",
      "            if cube.ndim > 1:\n",
      "                mod_name, model_full_name = get_model_name(cube, url)\n",
      "                cubes.update({mod_name: cube})\n",
      "            else:\n",
      "                log.warning('url {} is probably a timeSeries!'.format(url))\n",
      "        except (RuntimeError, ValueError, MergeError, TimeoutException,\n",
      "                ConstraintMismatchError, CoordinateNotFoundError) as e:\n",
      "            log.warning('Cannot get cube for: {}\\n{}'.format(url, e))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy.ma as ma\n",
      "from scipy.spatial import cKDTree as KDTree\n",
      "\n",
      "\n",
      "def standardize_fill_value(cube):\n",
      "    \"\"\"Work around default `fill_value` when obtaining\n",
      "    `_CubeSignature` (iris) using `lazy_data()` (biggus).\n",
      "    Warning use only when you DO KNOW that the slices should\n",
      "    have the same `fill_value`!!!\"\"\"\n",
      "    if ma.isMaskedArray(cube._my_data):\n",
      "        fill_value = ma.empty(0, dtype=cube._my_data.dtype).fill_value\n",
      "        cube._my_data.fill_value = fill_value\n",
      "    return cube\n",
      "\n",
      "\n",
      "def make_tree(cube):\n",
      "    \"\"\"Create KDTree.\"\"\"\n",
      "    lon = cube.coord(axis='X').points\n",
      "    lat = cube.coord(axis='Y').points\n",
      "    # Structured models with 1D lon, lat.\n",
      "    if (lon.ndim == 1) and (lat.ndim == 1) and (cube.ndim == 3):\n",
      "        lon, lat = np.meshgrid(lon, lat)\n",
      "    # Unstructure are already paired!\n",
      "    tree = KDTree(zip(lon.ravel(), lat.ravel()))\n",
      "    return tree, lon, lat\n",
      "\n",
      "\n",
      "def get_nearest_water(cube, tree, xi, yi, k=10, max_dist=0.04, min_var=0.01):\n",
      "    \"\"\"Find `k` nearest model data points from an iris `cube` at station\n",
      "    lon: `xi`, lat: `yi` up to `max_dist` in degrees.  Must provide a Scipy's\n",
      "    KDTree `tree`.\"\"\"\n",
      "    # TODO: Use rtree instead of KDTree.\n",
      "    # NOTE: Based on the iris `_nearest_neighbour_indices_ndcoords`.\n",
      "\n",
      "    distances, indices = tree.query(np.array([xi, yi]).T, k=k)\n",
      "    if indices.size == 0:\n",
      "        raise ValueError(\"No data found.\")\n",
      "    # Get data up to specified distance.\n",
      "    mask = distances <= max_dist\n",
      "    distances, indices = distances[mask], indices[mask]\n",
      "    if distances.size == 0:\n",
      "        msg = \"No data near ({}, {}) max_dist={}.\".format\n",
      "        raise ValueError(msg(xi, yi, max_dist))\n",
      "    # Unstructured model.\n",
      "    if (cube.coord(axis='X').ndim == 1) and (cube.ndim == 2):\n",
      "        i = j = indices\n",
      "        unstructured = True\n",
      "    # Structured model.\n",
      "    else:\n",
      "        unstructured = False\n",
      "        if cube.coord(axis='X').ndim == 2:  # CoordinateMultiDim\n",
      "            i, j = np.unravel_index(indices, cube.coord(axis='X').shape)\n",
      "        else:\n",
      "            shape = (cube.coord(axis='Y').shape[0],\n",
      "                     cube.coord(axis='X').shape[0])\n",
      "            i, j = np.unravel_index(indices, shape)\n",
      "    # Use only data where the standard deviation of the time series exceeds\n",
      "    # 0.01 m (1 cm) this eliminates flat line model time series that come from\n",
      "    # land points that should have had missing values.\n",
      "    series, dist, idx = None, None, None\n",
      "    for dist, idx in zip(distances, zip(i, j)):\n",
      "        if unstructured:  # NOTE: This would be so elegant in py3k!\n",
      "            idx = (idx[0],)\n",
      "        # This weird syntax allow for idx to be len 1 or 2.\n",
      "        series = cube[(slice(None),)+idx]\n",
      "        # Accounting for wet-and-dry models.\n",
      "        arr = ma.masked_invalid(series.data).filled(fill_value=0)\n",
      "        if arr.std() <= min_var:\n",
      "            series = None\n",
      "            break\n",
      "    return series, dist, idx\n",
      "\n",
      "\n",
      "def add_station(cube, station):\n",
      "    \"\"\"Add a station Auxiliary Coordinate and its name.\"\"\"\n",
      "    kw = dict(var_name=\"station\", long_name=\"station name\")\n",
      "    coord = iris.coords.AuxCoord(station, **kw)\n",
      "    cube.add_aux_coord(coord)\n",
      "    return cube\n",
      "\n",
      "\n",
      "def ensure_timeseries(cube):\n",
      "    \"\"\"Ensure that the cube is CF-timeSeries compliant.\"\"\"\n",
      "    if not cube.coord('time').shape == cube.shape[0]:\n",
      "        cube.transpose()\n",
      "    make_aux_coord(cube, axis='Y')\n",
      "    make_aux_coord(cube, axis='X')\n",
      "\n",
      "    cube.attributes.update({'featureType': 'timeSeries'})\n",
      "    cube.coord(\"station name\").attributes = dict(cf_role='timeseries_id')\n",
      "    return cube\n",
      "\n",
      "\n",
      "def make_aux_coord(cube, axis='Y'):\n",
      "    \"\"\"Make any given coordinate an Auxiliary Coordinate.\"\"\"\n",
      "    coord = cube.coord(axis=axis)\n",
      "    cube.remove_coord(coord)\n",
      "    if cube.ndim == 2:\n",
      "        cube.add_aux_coord(coord, 1)\n",
      "    else:\n",
      "        cube.add_aux_coord(coord)\n",
      "    return cube"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from iris.pandas import as_series\n",
      "\n",
      "\n",
      "for mod_name, cube in cubes.items():\n",
      "    fname = '{:%Y-%m-%d}-{}.nc'.format(stop, mod_name)\n",
      "    log.info(fmt(' Saving to file {} '.format(fname)))\n",
      "    # NOTE: 2D coords KDtree.  (Iris can only do 1D coords KDtree for now.)\n",
      "    try:\n",
      "        tree, lon, lat = make_tree(cube)\n",
      "    except CoordinateNotFoundError as e:\n",
      "        log.warning('Cannot create KDTree for: {}'.format(mod_name))\n",
      "        continue\n",
      "    # Get model series at observed locations.\n",
      "    raw_series = dict()\n",
      "    for station, obs in observations.iterrows():\n",
      "        try:\n",
      "            kw = dict(k=10, max_dist=0.04, min_var=0.01)\n",
      "            args = cube, tree, obs.lon, obs.lat\n",
      "            series, dist, idx = get_nearest_water(*args, **kw)\n",
      "        except ValueError as e:\n",
      "            log.warning(e)\n",
      "            continue\n",
      "        if not series:\n",
      "            status = \"Land \"\n",
      "        else:\n",
      "            raw_series.update({obs['station']: series})\n",
      "            series = as_series(series)\n",
      "            status = \"Water\"\n",
      "\n",
      "        log.info('[{}] {}'.format(status, obs.name))\n",
      "\n",
      "    if raw_series:  # Save cube.\n",
      "        for station, cube in raw_series.items():\n",
      "            cube = standardize_fill_value(cube)\n",
      "            cube = add_station(cube, station)\n",
      "        try:\n",
      "            cube = iris.cube.CubeList(raw_series.values()).merge_cube()\n",
      "        except MergeError as e:\n",
      "            log.warning(e)\n",
      "\n",
      "        ensure_timeseries(cube)\n",
      "        iris.save(cube, fname)\n",
      "        del cube\n",
      "\n",
      "    log.info('Finished processing [{}]: {}'.format(mod_name, url))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Add extra stations."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "include = dict({'Scituate, MA': dict(lon=-70.7166, lat=42.9259),\n",
      "                'Wells, ME': dict(lon=-70.583883, lat=43.272411)})\n",
      "\n",
      "models = dict()\n",
      "extra_series = dict()\n",
      "for station, obs in include.items():\n",
      "    for mod_name, cube in cubes.items():\n",
      "        mod_name, model_full_name = get_model_name(cube, url)\n",
      "        try:\n",
      "            tree, lon, lat = make_tree(cube)\n",
      "        except CoordinateNotFoundError as e:\n",
      "            log.warning('Cannot create KDTree for: {}'.format(mod_name))\n",
      "            continue\n",
      "        # Get model series at observed locations.\n",
      "        try:\n",
      "            kw = dict(k=10, max_dist=0.04, min_var=0.01)\n",
      "            args = cube, tree, obs['lon'], obs['lat']\n",
      "            series, dist, idx = get_nearest_water(*args, **kw)\n",
      "        except ValueError as e:\n",
      "            log.warning(e)\n",
      "            continue\n",
      "        if not series:\n",
      "            status = \"Land \"\n",
      "        else:\n",
      "            status = \"Water\"\n",
      "            models.update({mod_name: series})\n",
      "\n",
      "        log.info('[{}] {}'.format(status, station))\n",
      "    extra_series.update({station: models})\n",
      "    models = dict()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Load saved files and interpolate to the observations time interval"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from iris.pandas import as_data_frame\n",
      "\n",
      "\n",
      "def nc2df(fname):\n",
      "    cube = iris.load_cube(fname)\n",
      "    for coord in cube.coords(dimensions=[0]):\n",
      "        name = coord.name()\n",
      "        if name != 'time':\n",
      "            cube.remove_coord(name)\n",
      "    for coord in cube.coords(dimensions=[1]):\n",
      "        name = coord.name()\n",
      "        if name != 'station name':\n",
      "            cube.remove_coord(name)\n",
      "    df = as_data_frame(cube)\n",
      "    if cube.ndim == 1:  # Horrible work around iris.\n",
      "        station = cube.coord('station name').points[0]\n",
      "        df.columns = [station]\n",
      "    return df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from glob import glob\n",
      "from operator import itemgetter\n",
      "\n",
      "from pandas import Panel\n",
      "\n",
      "fname = '{}-OBS_DATA.nc'.format(run_name)\n",
      "OBS_DATA = nc2df(fname)\n",
      "OBS_DATA.index = OBS_DATA.index.tz_localize(start.tzinfo)\n",
      "\n",
      "from pandas import date_range\n",
      "index = date_range(start=start, end=stop, freq='6min', tz=start.tzinfo)\n",
      "\n",
      "dfs = dict(OBS_DATA=OBS_DATA)\n",
      "for fname in glob(\"*.nc\"):\n",
      "    if 'OBS_DATA' in fname:\n",
      "        continue\n",
      "    else:\n",
      "        model = fname.split('.')[0].split('-')[-1]\n",
      "        df = nc2df(fname)\n",
      "        if len(df.index.values) != len(np.unique(df.index.values)):\n",
      "            # FIXME: Horrible work around duplicate times.\n",
      "            opts = dict(cols='index', take_last=True)\n",
      "            df = df.reset_index().drop_duplicates(**opts).set_index('index')\n",
      "        df.index = df.index.tz_localize(start.tzinfo)\n",
      "        if False:  # if True interpolates to 6 min series.\n",
      "            kw = dict(method='time', limit=30)\n",
      "            df = df.reindex(index).interpolate(**kw).ix[index]\n",
      "        dfs.update({model: df})\n",
      "\n",
      "dfs = Panel.fromDict(dfs).swapaxes(0, 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Bias"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pandas import DataFrame\n",
      "\n",
      "panel = dfs.copy()\n",
      "means = dict()\n",
      "for station, df in panel.iteritems():\n",
      "    df.dropna(axis=1, how='all', inplace=True)\n",
      "    mean = df.mean()\n",
      "    df = df - mean + mean['OBS_DATA']\n",
      "    means.update({station: mean.drop('OBS_DATA') - mean['OBS_DATA']})\n",
      "\n",
      "bias = DataFrame.from_dict(means).dropna(axis=1, how='all')\n",
      "bias = bias.applymap('{:.2f}'.format).replace('nan', '--')\n",
      "\n",
      "columns = dict()\n",
      "[columns.update({station: get_coops_longname(station)}) for\n",
      " station in bias.columns.values]\n",
      "\n",
      "bias.rename(columns=columns, inplace=True)\n",
      "\n",
      "bias.T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>COAWST</th>\n",
        "      <th>ESTOFS</th>\n",
        "      <th>HYbrid</th>\n",
        "      <th>NECOFS</th>\n",
        "      <th>ROMS</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>Boston, MA</th>\n",
        "      <td>   --</td>\n",
        "      <td>    --</td>\n",
        "      <td>    --</td>\n",
        "      <td> 0.21</td>\n",
        "      <td>    --</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Chatham, MA</th>\n",
        "      <td>   --</td>\n",
        "      <td> -0.15</td>\n",
        "      <td> -0.74</td>\n",
        "      <td> 0.01</td>\n",
        "      <td>    --</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Woods Hole, MA</th>\n",
        "      <td> 0.13</td>\n",
        "      <td> -0.06</td>\n",
        "      <td>    --</td>\n",
        "      <td> 0.23</td>\n",
        "      <td>    --</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Newport, RI</th>\n",
        "      <td> 0.16</td>\n",
        "      <td> -0.09</td>\n",
        "      <td>    --</td>\n",
        "      <td> 0.31</td>\n",
        "      <td> -0.35</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Providence, RI</th>\n",
        "      <td>   --</td>\n",
        "      <td>    --</td>\n",
        "      <td>    --</td>\n",
        "      <td> 0.28</td>\n",
        "      <td>    --</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Montauk, NY</th>\n",
        "      <td>   --</td>\n",
        "      <td> -0.11</td>\n",
        "      <td>    --</td>\n",
        "      <td> 0.28</td>\n",
        "      <td>    --</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "               COAWST ESTOFS HYbrid NECOFS   ROMS\n",
        "Boston, MA         --     --     --   0.21     --\n",
        "Chatham, MA        --  -0.15  -0.74   0.01     --\n",
        "Woods Hole, MA   0.13  -0.06     --   0.23     --\n",
        "Newport, RI      0.16  -0.09     --   0.31  -0.35\n",
        "Providence, RI     --     --     --   0.28     --\n",
        "Montauk, NY        --  -0.11     --   0.28     --"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Model skill"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def both_valid(x, y):\n",
      "    \"\"\"Returns a mask where both series are valid.\"\"\"\n",
      "    mask_x = np.isnan(x)\n",
      "    mask_y = np.isnan(y)\n",
      "    return np.logical_and(~mask_x, ~mask_y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats.stats import pearsonr\n",
      "\n",
      "\n",
      "skills = dict()\n",
      "for station, df in panel.iteritems():\n",
      "    obs = df['OBS_DATA']\n",
      "    skill = dict()\n",
      "    for model, y in df.iteritems():\n",
      "        if 'OBS_DATA' not in model:\n",
      "            mask = both_valid(obs, y)\n",
      "            r, p = pearsonr(obs[mask]-obs.mean(), y[mask]-y.mean())\n",
      "            skill.update({model: r})\n",
      "    skills.update({station: skill})\n",
      "\n",
      "df = DataFrame.from_dict(skills)\n",
      "\n",
      "columns = dict()\n",
      "[columns.update({station: get_coops_longname(station)}) for\n",
      " station in df.columns.values]\n",
      "\n",
      "df.rename(columns=columns, inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fname = 'skill.html'\n",
      "\n",
      "df_skill = df.applymap('{:.2f}'.format).replace('nan', '--')\n",
      "\n",
      "df_skill.T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>COAWST</th>\n",
        "      <th>ESTOFS</th>\n",
        "      <th>HYbrid</th>\n",
        "      <th>NECOFS</th>\n",
        "      <th>ROMS</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>Boston, MA</th>\n",
        "      <td>   --</td>\n",
        "      <td>   --</td>\n",
        "      <td>   --</td>\n",
        "      <td> 0.99</td>\n",
        "      <td>   --</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Chatham, MA</th>\n",
        "      <td>   --</td>\n",
        "      <td> 0.90</td>\n",
        "      <td> 0.32</td>\n",
        "      <td> 0.95</td>\n",
        "      <td>   --</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Woods Hole, MA</th>\n",
        "      <td> 0.79</td>\n",
        "      <td> 0.83</td>\n",
        "      <td>   --</td>\n",
        "      <td> 0.70</td>\n",
        "      <td>   --</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Newport, RI</th>\n",
        "      <td> 0.83</td>\n",
        "      <td> 0.90</td>\n",
        "      <td>   --</td>\n",
        "      <td> 0.97</td>\n",
        "      <td> 0.88</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Providence, RI</th>\n",
        "      <td>   --</td>\n",
        "      <td>   --</td>\n",
        "      <td>   --</td>\n",
        "      <td> 0.95</td>\n",
        "      <td>   --</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Montauk, NY</th>\n",
        "      <td>   --</td>\n",
        "      <td> 0.93</td>\n",
        "      <td>   --</td>\n",
        "      <td> 0.95</td>\n",
        "      <td>   --</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "               COAWST ESTOFS HYbrid NECOFS  ROMS\n",
        "Boston, MA         --     --     --   0.99    --\n",
        "Chatham, MA        --   0.90   0.32   0.95    --\n",
        "Woods Hole, MA   0.79   0.83     --   0.70    --\n",
        "Newport, RI      0.83   0.90     --   0.97  0.88\n",
        "Providence, RI     --     --     --   0.95    --\n",
        "Montauk, NY        --   0.93     --   0.95    --"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Map"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from folium.folium import Map\n",
      "import matplotlib.pyplot as plt\n",
      "from IPython.display import IFrame\n",
      "\n",
      "\n",
      "def get_coordinates(bbox):\n",
      "    \"\"\"Create bounding box coordinates for the map.  It takes flat or\n",
      "    nested list/numpy.array and returns 4 points for the map corners.\"\"\"\n",
      "    bbox = np.asanyarray(bbox).ravel()\n",
      "    if bbox.size == 4:\n",
      "        bbox = bbox.reshape(2, 2)\n",
      "        coordinates = []\n",
      "        coordinates.append([bbox[0][1], bbox[0][0]])\n",
      "        coordinates.append([bbox[0][1], bbox[1][0]])\n",
      "        coordinates.append([bbox[1][1], bbox[1][0]])\n",
      "        coordinates.append([bbox[1][1], bbox[0][0]])\n",
      "        coordinates.append([bbox[0][1], bbox[0][0]])\n",
      "    else:\n",
      "        raise ValueError('Wrong number corners.'\n",
      "                         '  Expected 4 got {}'.format(bbox.size))\n",
      "    return coordinates\n",
      "\n",
      "\n",
      "def inline_map(m):\n",
      "    \"\"\"Takes a folium instance or a html path and load into an iframe.\"\"\"\n",
      "    if isinstance(m, Map):\n",
      "        m._build_map()\n",
      "        srcdoc = m.HTML.replace('\"', '&quot;')\n",
      "        embed = HTML('<iframe srcdoc=\"{srcdoc}\" '\n",
      "                     'style=\"width: 100%; height: 500px; '\n",
      "                     'border: none\"></iframe>'.format(srcdoc=srcdoc))\n",
      "    elif isinstance(m, str):\n",
      "        embed = IFrame(m, width=750, height=500)\n",
      "    return embed\n",
      "\n",
      "\n",
      "def make_map(bbox, **kw):\n",
      "    \"\"\"Creates a folium map instance.\"\"\"\n",
      "    line = kw.pop('line', True)\n",
      "    zoom_start = kw.pop('zoom_start', 7)\n",
      "\n",
      "    lon, lat = np.array(bbox).reshape(2, 2).mean(axis=0)\n",
      "    m = Map(width=750, height=500,\n",
      "            location=[lat, lon], zoom_start=zoom_start)\n",
      "    if line:\n",
      "        # Create the map and add the bounding box line.\n",
      "        kw = dict(line_color='#FF0000', line_weight=2)\n",
      "        m.line(get_coordinates(bbox), **kw)\n",
      "    return m\n",
      "\n",
      "\n",
      "def plot_series():\n",
      "    fig, ax = plt.subplots(figsize=(width, height))\n",
      "    ax.set_ylabel('Sea surface height (m)')\n",
      "    ax.set_ylim(-2.5, 2.5)\n",
      "    ax.grid(True)\n",
      "    return fig, ax"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Clusters.\n",
      "big_list = []\n",
      "for fname in glob(\"*.nc\"):\n",
      "    if 'OBS_DATA' in fname:\n",
      "        continue\n",
      "    nc = iris.load_cube(fname)\n",
      "    model = fname.split('-')[-1].split('.')[0]\n",
      "    lons = nc.coord(axis='X').points\n",
      "    lats = nc.coord(axis='Y').points\n",
      "    stations = nc.coord('station name').points\n",
      "    models = [model]*lons.size\n",
      "    lista = zip(models, lons.tolist(), lats.tolist(), stations.tolist())\n",
      "    big_list.extend(lista)\n",
      "\n",
      "big_list.sort(key=itemgetter(3))\n",
      "df = DataFrame(big_list, columns=['name', 'lon', 'lat', 'station'])\n",
      "df.set_index('station', drop=True, inplace=True)\n",
      "groups = df.groupby(df.index)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mpld3 import save_html\n",
      "from mpld3.plugins import LineLabelTooltip, connect\n",
      "\n",
      "mapa = make_map(bbox, line=True, states=False)\n",
      "\n",
      "# Clusters.\n",
      "for station, info in groups:\n",
      "    station = get_coops_longname(station)\n",
      "    for lat, lon, name in zip(info.lat, info.lon, info.name):\n",
      "        location = lat, lon\n",
      "        popup = '<b>{}</b>\\n{}'.format(station, name)\n",
      "        mapa.simple_marker(location=location, popup=popup,\n",
      "                           clustered_marker=True)\n",
      "\n",
      "# Model and observations.\n",
      "resolution, width, height = 75, 7, 3\n",
      "for station in dfs:\n",
      "    sta_name = get_coops_longname(station)\n",
      "    # This will eliminate all NaNs columns.\n",
      "    df = dfs[station].dropna(axis=1, how='all')\n",
      "\n",
      "    fig, ax = plot_series()\n",
      "    labels = []\n",
      "    for col in df.columns:\n",
      "        # This restore the series to its original \"index.\"\n",
      "        # Not needed if interpolating the series.\n",
      "        serie = df[col].dropna()\n",
      "        lines = ax.plot(serie.index, serie, label=col,\n",
      "                        linewidth=2.5, alpha=0.5)\n",
      "        if 'OBS_DATA' not in col:\n",
      "            text0 = col\n",
      "            text1 = bias[sta_name][col]\n",
      "            text2 = df_skill[sta_name][col]\n",
      "            tooltip = '{}:\\nbias {}\\nskill: {}'.format\n",
      "            labels.append(tooltip(text0, text1, text2))\n",
      "        else:\n",
      "            labels.append('OBS_DATA')\n",
      "\n",
      "    kw = dict(loc='upper center', bbox_to_anchor=(0.5, 1.05), numpoints=1,\n",
      "              ncol=2, framealpha=0)\n",
      "    l = ax.legend(**kw)\n",
      "    l.set_title(\"\")  # Workaround str(None).\n",
      "\n",
      "    [connect(fig, LineLabelTooltip(line, name))\n",
      "     for line, name in zip(ax.lines, labels)]\n",
      "\n",
      "    html = 'station_{}.html'.format(station)\n",
      "    save_html(fig, '{}'.format(html))\n",
      "\n",
      "    popup = \"<div align='center'> {} <br><iframe src='{}' alt='image'\"\n",
      "    popup += \"width='{}px' height='{}px' frameBorder='0'></div>\"\n",
      "    popup = popup.format('{}'.format(sta_name), html,\n",
      "                         (width*resolution)+75, (height*resolution)+50)\n",
      "    kw = dict(popup=popup, width=(width*resolution)+75)\n",
      "\n",
      "    if (df.columns == 'OBS_DATA').all():\n",
      "        kw.update(dict(marker_color=\"blue\", marker_icon=\"ok\"))\n",
      "    else:\n",
      "        kw.update(dict(marker_color=\"green\", marker_icon=\"ok-sign\"))\n",
      "    obs = observations[observations['station'] == station].squeeze()\n",
      "    mapa.simple_marker(location=[obs['lat'], obs['lon']], **kw)\n",
      "\n",
      "# Bad datum.\n",
      "if isinstance(bad_datum, DataFrame):\n",
      "    for station, obs in bad_datum.iterrows():\n",
      "        popup = '<b>Station:</b> {}<br><b>Datum:</b> {}<br>'\n",
      "        popup = popup.format(station, obs['datum'])\n",
      "        kw = dict(popup=popup, marker_color=\"red\", marker_icon=\"question-sign\")\n",
      "        mapa.simple_marker(location=[obs['lat'], obs['lon']], **kw)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for station in include.keys():\n",
      "    models = extra_series[station]\n",
      "    if models:\n",
      "        fig, ax = plot_series()\n",
      "        labels = []\n",
      "        for model, cube in models.items():\n",
      "            t = time_coord(cube)\n",
      "            t = t.units.num2date(t.points)\n",
      "            lines = ax.plot(t, cube.data, linewidth=2.5, alpha=0.5,\n",
      "                            label=model)\n",
      "            labels.append(model)\n",
      "\n",
      "        kw = dict(loc='upper center', bbox_to_anchor=(0.5, 1.05), numpoints=1,\n",
      "                  ncol=2, framealpha=0)\n",
      "        l = ax.legend(**kw)\n",
      "        l.set_title(\"\")  # Workaround str(None).\n",
      "\n",
      "        [connect(fig, LineLabelTooltip(line, name))\n",
      "         for line, name in zip(ax.lines, labels)]\n",
      "\n",
      "        html = 'station_{}.html'.format\n",
      "        html = html(station.lower().replace(' ', '_').replace(',', ''))\n",
      "        save_html(fig, '{}'.format(html))\n",
      "\n",
      "        popup = \"<div align='center'> {} <br><iframe src='{}' alt='image'\"\n",
      "        popup += \"width='{}px' height='{}px' frameBorder='0'></div>\"\n",
      "        popup = popup.format('{}'.format(sta_name), html,\n",
      "                             (width*resolution)+75, (height*resolution)+50)\n",
      "        kw = dict(popup=popup, width=(width*resolution)+75)\n",
      "\n",
      "        kw.update(dict(marker_color=\"green\", marker_icon=\"ok\"))\n",
      "        obs = observations[observations['station'] == station].squeeze()\n",
      "        mapa.simple_marker(location=[include[station]['lat'],\n",
      "                                     include[station]['lon']], **kw)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mapa.create_map(path='mapa.html')\n",
      "inline_map('mapa.html')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "\n",
        "        <iframe\n",
        "            width=\"750\"\n",
        "            height=500\"\n",
        "            src=\"mapa.html\"\n",
        "            frameborder=\"0\"\n",
        "            allowfullscreen\n",
        "        ></iframe>\n",
        "        "
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "<IPython.lib.display.IFrame at 0x7f8a40c933d0>"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "elapsed = time.time() - start_time\n",
      "log.info('{:.2f} minutes'.format(elapsed/60.))\n",
      "log.info('EOF')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('log.txt') as f:\n",
      "    print(f.read())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10:38:47 INFO: *********************** Run information ************************\n",
        "10:38:47 INFO: Run date: 2015-01-27 13:38:47\n",
        "10:38:47 INFO: Download start: 2015-01-23 12:00:00\n",
        "10:38:47 INFO: Download stop: 2015-01-30 12:00:00\n",
        "10:38:47 INFO: Bounding box: -72.00, 41.00,-69.00, 43.00\n",
        "10:38:47 INFO: *********************** Software version ***********************\n",
        "10:38:47 INFO: Iris version: 1.7.2-DEV\n",
        "10:38:47 INFO: owslib version: 0.8-dev\n",
        "10:38:47 INFO: pyoos version: 0.6.2\n",
        "10:38:52 INFO: ********************* Catalog information **********************\n",
        "10:38:52 INFO: URL: http://www.ngdc.noaa.gov/geoportal/csw\n",
        "10:38:52 INFO: CSW version: 2.0.2\n",
        "10:38:52 INFO: Number of datasets available: 7\n",
        "10:38:52 INFO: ***************************** CSW ******************************\n",
        "10:38:52 INFO: NECOFS Massachusetts (FVCOM) - Massachusetts Coastal - Latest Forecast\n",
        "10:38:52 INFO: ROMS ESPRESSO Real-Time Operational IS4DVAR Forecast System Version 2 (NEW) 2013-present FMRC History (Best)\n",
        "10:38:52 INFO: NECOFS GOM3 (FVCOM) - Northeast US - Latest Forecast\n",
        "10:38:52 INFO: COAWST Forecast System : USGS : US East Coast and Gulf of Mexico (Experimental)\n",
        "10:38:52 INFO: Barotropic Tide Model for the Pacific Basin\n",
        "10:38:52 INFO: ESTOFS Storm Surge Model - Atlantic - v1.0.0 - NOAA - NCEP - ADCIRC\n",
        "10:38:52 INFO: HYbrid Coordinate Ocean Model (HYCOM): Global\n",
        "10:38:52 INFO: ***************************** DAP ******************************\n",
        "10:38:52 INFO: http://geoport-dev.whoi.edu/thredds/dodsC/estofs/atlantic.html\n",
        "10:38:52 INFO: http://geoport.whoi.edu/thredds/dodsC/coawst_4/use/fmrc/coawst_4_use_best.ncd.html\n",
        "10:38:52 INFO: http://oos.soest.hawaii.edu/thredds/dodsC/hioos/tide_pac.html\n",
        "10:38:52 INFO: http://oos.soest.hawaii.edu/thredds/dodsC/pacioos/hycom/global.html\n",
        "10:38:52 INFO: http://tds.marine.rutgers.edu/thredds/dodsC/roms/espresso/2013_da/his_Best/ESPRESSO_Real-Time_v2_History_Best_Available_best.ncd.html\n",
        "10:38:52 INFO: http://www.smast.umassd.edu:8080/thredds/dodsC/FVCOM/NECOFS/Forecasts/NECOFS_FVCOM_OCEAN_MASSBAY_FORECAST.nc.html\n",
        "10:38:52 INFO: http://www.smast.umassd.edu:8080/thredds/dodsC/FVCOM/NECOFS/Forecasts/NECOFS_GOM3_FORECAST.nc.html\n",
        "10:38:52 INFO: ***************************** SOS ******************************\n",
        "10:39:00 INFO: ********************* Collector offerings **********************\n",
        "10:39:00 INFO: NOAA.NOS.CO-OPS SOS: 1030 offerings\n",
        "10:39:01 INFO: Starting new HTTP connection (1): opendap.co-ops.nos.noaa.gov\n",
        "10:39:02 INFO: SOS URL request: http://opendap.co-ops.nos.noaa.gov/ioos-dif-sos/SOS?eventTime=2015-01-23T12%3A00%3A00Z&service=SOS&offering=urn%3Aioos%3Anetwork%3ANOAA.NOS.CO-OPS%3AWaterLevelActive&request=GetObservation&version=1.0.0&responseFormat=text%2Fcsv&featureOfInterest=BBOX%3A-72.0%2C41.0%2C-69.0%2C43.0&observedProperty=water_surface_height_above_reference_datum\n",
        "10:39:11 INFO: ************************* Observations *************************\n",
        "10:39:11 INFO: ********** Downloading to file 2015-01-30-OBS_DATA.nc **********\n",
        "10:39:16 WARNING: [8447386] Fall River, MA:\n",
        "'Wrong Datum for this station: The correct Datum values are: MHHW, MHW, MTL, MSL, MLW, MLLW, STND'\n",
        "10:39:26 WARNING: [8449130] Nantucket Island, MA:\n",
        "'Wrong Datum for this station: The correct Datum values are: MHHW, MHW, MTL, MSL, MLW, MLLW, STND'\n",
        "10:39:32 WARNING: [8452944] Conimicut Light, RI:\n",
        "'Wrong Datum for this station: The correct Datum values are: MHHW, MHW, MTL, MSL, MLW, MLLW, STND'\n",
        "10:39:43 INFO: **************************** Models ****************************\n",
        "10:39:43 INFO: \n",
        "[Reading url 1/7]: http://geoport-dev.whoi.edu/thredds/dodsC/estofs/atlantic\n",
        "10:41:31 INFO: \n",
        "[Reading url 2/7]: http://geoport.whoi.edu/thredds/dodsC/coawst_4/use/fmrc/coawst_4_use_best.ncd\n",
        "10:42:36 INFO: \n",
        "[Reading url 3/7]: http://oos.soest.hawaii.edu/thredds/dodsC/hioos/tide_pac\n",
        "10:42:48 INFO: \n",
        "[Reading url 4/7]: http://oos.soest.hawaii.edu/thredds/dodsC/pacioos/hycom/global\n",
        "10:42:52 INFO: \n",
        "[Reading url 5/7]: http://tds.marine.rutgers.edu/thredds/dodsC/roms/espresso/2013_da/his_Best/ESPRESSO_Real-Time_v2_History_Best_Available_best.ncd\n",
        "10:43:06 INFO: \n",
        "[Reading url 6/7]: http://www.smast.umassd.edu:8080/thredds/dodsC/FVCOM/NECOFS/Forecasts/NECOFS_FVCOM_OCEAN_MASSBAY_FORECAST.nc\n",
        "10:43:28 INFO: \n",
        "[Reading url 7/7]: http://www.smast.umassd.edu:8080/thredds/dodsC/FVCOM/NECOFS/Forecasts/NECOFS_GOM3_FORECAST.nc\n",
        "10:43:41 INFO: ************* Saving to file 2015-01-30-ESTOFS.nc **************\n",
        "10:43:41 WARNING: No data near (-71.0534, 42.3548) max_dist=0.04.\n",
        "10:43:46 INFO: [Water] Chatham, MA\n",
        "10:43:57 INFO: [Water] Woods Hole, MA\n",
        "10:44:07 INFO: [Water] Newport, RI\n",
        "10:44:07 WARNING: No data near (-71.4012, 41.8071) max_dist=0.04.\n",
        "10:44:18 INFO: [Water] Montauk, NY\n",
        "10:44:18 INFO: Finished processing [ESTOFS]: http://www.smast.umassd.edu:8080/thredds/dodsC/FVCOM/NECOFS/Forecasts/NECOFS_GOM3_FORECAST.nc\n",
        "10:44:18 INFO: ************** Saving to file 2015-01-30-ROMS.nc ***************\n",
        "10:44:21 INFO: [Land ] Boston, MA\n",
        "10:44:24 INFO: [Land ] Chatham, MA\n",
        "10:44:27 INFO: [Land ] Woods Hole, MA\n",
        "10:44:30 INFO: [Water] Newport, RI\n",
        "10:44:33 INFO: [Land ] Providence, RI\n",
        "10:44:36 INFO: [Land ] Montauk, NY\n",
        "10:44:39 INFO: Finished processing [ROMS]: http://www.smast.umassd.edu:8080/thredds/dodsC/FVCOM/NECOFS/Forecasts/NECOFS_GOM3_FORECAST.nc\n",
        "10:44:39 INFO: *********** Saving to file 2015-01-30-Barotropic.nc ************\n",
        "10:44:39 WARNING: No data near (-71.0534, 42.3548) max_dist=0.04.\n",
        "10:44:39 WARNING: No data near (-69.9511, 41.6885) max_dist=0.04.\n",
        "10:44:39 WARNING: No data near (-70.6717, 41.5233) max_dist=0.04.\n",
        "10:44:39 WARNING: No data near (-71.3267, 41.505) max_dist=0.04.\n",
        "10:44:39 WARNING: No data near (-71.4012, 41.8071) max_dist=0.04.\n",
        "10:44:39 WARNING: No data near (-71.96, 41.0483) max_dist=0.04.\n",
        "10:44:39 INFO: Finished processing [Barotropic]: http://www.smast.umassd.edu:8080/thredds/dodsC/FVCOM/NECOFS/Forecasts/NECOFS_GOM3_FORECAST.nc\n",
        "10:44:39 INFO: ************* Saving to file 2015-01-30-COAWST.nc **************\n",
        "10:44:48 INFO: [Land ] Boston, MA\n",
        "10:44:54 INFO: [Land ] Chatham, MA\n",
        "10:44:59 INFO: [Water] Woods Hole, MA\n",
        "10:45:11 INFO: [Water] Newport, RI\n",
        "10:45:17 INFO: [Land ] Providence, RI\n",
        "10:45:29 INFO: [Land ] Montauk, NY\n",
        "10:45:41 INFO: Finished processing [COAWST]: http://www.smast.umassd.edu:8080/thredds/dodsC/FVCOM/NECOFS/Forecasts/NECOFS_GOM3_FORECAST.nc\n",
        "10:45:41 INFO: ************* Saving to file 2015-01-30-HYbrid.nc **************\n",
        "10:45:45 INFO: [Land ] Boston, MA\n",
        "10:45:47 INFO: [Water] Chatham, MA\n",
        "10:45:47 WARNING: No data near (-70.6717, 41.5233) max_dist=0.04.\n",
        "10:45:51 INFO: [Land ] Newport, RI\n",
        "10:45:51 WARNING: No data near (-71.4012, 41.8071) max_dist=0.04.\n",
        "10:45:51 WARNING: No data near (-71.96, 41.0483) max_dist=0.04.\n",
        "10:45:51 INFO: Finished processing [HYbrid]: http://www.smast.umassd.edu:8080/thredds/dodsC/FVCOM/NECOFS/Forecasts/NECOFS_GOM3_FORECAST.nc\n",
        "10:45:51 INFO: ************* Saving to file 2015-01-30-NECOFS.nc **************\n",
        "10:46:05 INFO: [Water] Boston, MA\n",
        "10:46:19 INFO: [Water] Chatham, MA\n",
        "10:46:33 INFO: [Water] Woods Hole, MA\n",
        "10:46:47 INFO: [Water] Newport, RI\n",
        "10:47:00 INFO: [Water] Providence, RI\n",
        "10:47:16 INFO: [Water] Montauk, NY\n",
        "10:47:16 INFO: Finished processing [NECOFS]: http://www.smast.umassd.edu:8080/thredds/dodsC/FVCOM/NECOFS/Forecasts/NECOFS_GOM3_FORECAST.nc\n",
        "10:47:28 INFO: [Water] Scituate, MA\n",
        "10:47:28 WARNING: No data near (-70.7166, 42.9259) max_dist=0.04.\n",
        "10:47:28 WARNING: No data near (-70.7166, 42.9259) max_dist=0.04.\n",
        "10:47:42 INFO: [Water] Scituate, MA\n",
        "10:47:45 INFO: [Water] Scituate, MA\n",
        "10:47:59 INFO: [Water] Scituate, MA\n",
        "10:47:59 WARNING: No data near (-70.583883, 43.272411) max_dist=0.04.\n",
        "10:47:59 WARNING: No data near (-70.583883, 43.272411) max_dist=0.04.\n",
        "10:47:59 WARNING: No data near (-70.583883, 43.272411) max_dist=0.04.\n",
        "10:48:05 INFO: [Land ] Wells, ME\n",
        "10:48:05 WARNING: No data near (-70.583883, 43.272411) max_dist=0.04.\n",
        "10:48:05 WARNING: No data near (-70.583883, 43.272411) max_dist=0.04.\n",
        "10:48:05 WARNING: /home/filipe/miniconda/envs/SECOORA/lib/python2.7/site-packages/pandas/util/decorators.py:81: FutureWarning: the 'cols' keyword is deprecated, use 'subset' instead\n",
        "  warnings.warn(msg, FutureWarning)\n",
        "\n",
        "10:48:32 INFO: 9.76 minutes\n",
        "10:48:32 INFO: EOF\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 33
    }
   ],
   "metadata": {}
  }
 ]
}